{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Testing LoRa with GPT2-Medium for finetuning",
   "id": "24db587424c051ff"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Importing necessary libraries",
   "id": "4651ce240c07d5fd"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gpt2_medium import Trainer\n",
    "from labml import experiment\n",
    "import torch"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Check use of GPU, this could be performed with CPU, however it will take more time",
   "id": "7f0fe43db1226960"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "experiment.create(name=\"lora_gpt2\")\n",
    "if torch.cuda.is_available():\n",
    "    print(\"Executing with cuda (GPU)\")"
   ],
   "id": "8630478fc30b2881"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Initialize\n",
    "\n",
    "Here we are loading all the information about the model, the iterations and batch size for LoRa as well as the \"r\" used for the A and B submatrixes"
   ],
   "id": "5b5c4c9dd6889309"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "trainer = Trainer()\n",
    "\n",
    "experiment.configs(trainer)\n",
    "\n",
    "trainer.initialize()"
   ],
   "id": "655ab91f22992216"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Start the experiment\n",
    "In this section we will compare simple finetuning vs LoRa in different aspects"
   ],
   "id": "fc392a8e1eca44b6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "lora_results = trainer.lora_finetuning()\n",
    "simple_finetune_results = trainer.simple_finetuning()\n"
   ],
   "id": "3d7ab7f60f2b3bce"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Compare the results when modifying R",
   "id": "368039956141ecf1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Plot improvements with increasing R\n",
    "trainer.plot_lora_improvement(lora_results)"
   ],
   "id": "a3f74c553cf20c1e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Compare the results between LoRa and simple FT",
   "id": "1eeaf73baabb616b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Plot comparison between LoRa and simple fine-tuning\n",
    "trainer.plot_finetune_vs_lora(lora_results, simple_finetune_results)"
   ],
   "id": "e1b938294601e4f3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Compare the time needed for LoRa vs simple FT",
   "id": "1b243465cd49cb12"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Plot time comparison between LoRa and fine-tuning\n",
    "trainer.plot_time_comparison(lora_results, simple_finetune_results)"
   ],
   "id": "819edf7c7d9822fe"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
